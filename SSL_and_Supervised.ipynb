{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"SSL_and_Supervised.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b08d9ff6dcad4dcab5e54a001614f863":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ab140b1fd20c4df4b5cda9a3215ed13f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_06987b938997430dbe31dd08cb06847c","IPY_MODEL_477988b62d454249a067b75b590ce1f1","IPY_MODEL_646106f4847d4797a44a2ed53ac33030"]}},"ab140b1fd20c4df4b5cda9a3215ed13f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"06987b938997430dbe31dd08cb06847c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_517529527e6048b7ae554c7c7b2fd3ae","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e156fd40458b4526b5b57f92818c3d6b"}},"477988b62d454249a067b75b590ce1f1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cb32dfbe2d3e47bba40df0e62a286fa3","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":170498071,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":170498071,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cd17095258504cfcafcb5b0a7cd72df3"}},"646106f4847d4797a44a2ed53ac33030":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0eed604eda63427cb1773661c4ad21a1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170499072/? [00:06&lt;00:00, 31204231.79it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8853432e218c459eb22d22146dc25475"}},"517529527e6048b7ae554c7c7b2fd3ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e156fd40458b4526b5b57f92818c3d6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cb32dfbe2d3e47bba40df0e62a286fa3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cd17095258504cfcafcb5b0a7cd72df3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0eed604eda63427cb1773661c4ad21a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8853432e218c459eb22d22146dc25475":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"eSfMydtVwgWO"},"source":["## 練習自監督學習，內含四種自監督學習演算法SimCLR, MoCo, BYOL, BarlowTwins（也包含最基本的監督式學習訓練方法）"]},{"cell_type":"code","metadata":{"id":"Tt405IfmWRe8"},"source":["import time\n","import math\n","import numpy as np\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import pandas as pd\n","import torchvision\n","import torchvision.datasets as datasets\n","from torchvision.models.resnet import resnet50, resnet18\n","from PIL import Image\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZNVjb8NzhFJI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638445972404,"user_tz":-480,"elapsed":516,"user":{"displayName":"林同軒","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17956594846841709825"}},"outputId":"e9d21b4b-affc-4465-df1b-77ce7be6988f"},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)\n","\n","! nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n","Thu Dec  2 11:52:51 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P8    27W / 149W |      3MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"mAIRRb-nWZZ0"},"source":["# 定義圖片變換(SSL要比較高強度的圖片變換)\n","\n","SSL_train_transform = transforms.Compose([\n","    transforms.RandomResizedCrop(32),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n","    transforms.RandomGrayscale(p=0.2),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n","\n","supervised_train_transform = transforms.Compose([\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n","\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fLQG9gQlZKtc"},"source":["# # 印出圖片看看transform的作用\n","\n","# import matplotlib.pyplot as plt\n","\n","# def imshow(img):\n","#     img[0] = img[0] * 0.2023 + 0.4914    \n","#     img[1] = img[1] * 0.1994 + 0.4822  \n","#     img[2] = img[2] * 0.2010 + 0.4465    \n","#     npimg = img.numpy()\n","#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","#     plt.show()\n","\n","# batch_size = 5\n","# stl10_classes = ('airplane', 'bird', 'car', 'cat', 'deer', 'dog', 'horse', 'monkey', 'ship', 'truck')\n","# train_data_temp = datasets.STL10(root='./dataset', split='train', transform=train_transform, download=True)\n","# train_loader = DataLoader(train_data_temp, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n","\n","# # get some random training images\n","# dataiter = iter(train_loader)\n","# images, labels = dataiter.next()\n","\n","# # show images\n","# # imshow(torchvision.utils.make_grid(images)) # 32*32 pixel\n","# for im in images:\n","#   imshow(im)\n","# # print labels\n","# print(' '.join('%5s' % stl10_classes[labels[j]] for j in range(batch_size)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SLKudJopWJHu"},"source":["# 定義模型\n","class SSL_ResNet50(nn.Module):\n","    def __init__(self, feature_dim=128):\n","        super(SSL_ResNet50, self).__init__()\n","\n","        self.f = []\n","        for name, module in resnet50().named_children():\n","            if name == 'conv1':\n","                module = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","            if not isinstance(module, nn.Linear) and not isinstance(module, nn.MaxPool2d):\n","                self.f.append(module)\n","        # encoder\n","        self.f = nn.Sequential(*self.f)\n","        # projection head\n","        self.g = nn.Sequential(nn.Linear(2048, 512, bias=False), nn.BatchNorm1d(512),\n","                               nn.ReLU(inplace=True), nn.Linear(512, feature_dim, bias=True))\n","\n","    def forward(self, x):\n","        x = self.f(x)\n","        feature = torch.flatten(x, start_dim=1)\n","        out = self.g(feature)\n","        return F.normalize(feature, dim=-1), F.normalize(out, dim=-1)\n","\n","class SSL_ResNet18(nn.Module): # SimCLR, MoCo\n","    def __init__(self, feature_dim=128):\n","        super(SSL_ResNet18, self).__init__()\n","\n","        self.f = []\n","        for name, module in resnet18().named_children():\n","            if name == 'conv1':\n","                module = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","            if not isinstance(module, nn.Linear) and not isinstance(module, nn.MaxPool2d):\n","                self.f.append(module)\n","        # encoder\n","        self.f = nn.Sequential(*self.f)\n","        # projection head\n","        self.g = nn.Sequential(nn.Linear(512, 512, bias=False), nn.BatchNorm1d(512),\n","                               nn.ReLU(inplace=True), nn.Linear(512, feature_dim, bias=True))\n","\n","    def forward(self, x):\n","        x = self.f(x)\n","        feature = torch.flatten(x, start_dim=1)\n","        out = self.g(feature)\n","        return F.normalize(feature, dim=-1), F.normalize(out, dim=-1)\n","\n","class BYOL_ResNet18(nn.Module):\n","    def __init__(self, feature_dim=128):\n","        super(BYOL_ResNet18, self).__init__()\n","\n","        self.f = []\n","        for name, module in resnet18().named_children():\n","            if name == 'conv1':\n","                module = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","            if not isinstance(module, nn.Linear) and not isinstance(module, nn.MaxPool2d):\n","                self.f.append(module)\n","        # encoder\n","        self.f = nn.Sequential(*self.f)\n","        # projection head\n","        self.g = nn.Sequential(nn.Linear(512, 512, bias=False), nn.BatchNorm1d(512),\n","                               nn.ReLU(inplace=True), nn.Linear(512, feature_dim, bias=True))\n","\n","    def forward(self, x):\n","        x = self.f(x)\n","        feature = torch.flatten(x, start_dim=1)\n","        out = self.g(feature)\n","        return F.normalize(feature, dim=-1), out # the different is output, no normalization\n","\n","class Prediction_Layer(nn.Module): # for BYOL, just a simple MLP layer\n","    def __init__(self, in_channels=128, hidden_size=512, output_size=128):\n","        super(Prediction_Layer, self).__init__()\n","\n","        self.net = nn.Sequential(\n","            nn.Linear(in_channels, hidden_size),\n","            nn.BatchNorm1d(hidden_size),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(hidden_size, output_size)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","\n","class BarlowTwins_ResNet18(nn.Module):\n","    def __init__(self, feature_dim=1024):\n","        super(BarlowTwins_ResNet18, self).__init__()\n","\n","        self.f = []\n","        for name, module in resnet18().named_children():\n","            if name == 'conv1':\n","                module = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","            if not isinstance(module, nn.Linear) and not isinstance(module, nn.MaxPool2d):\n","                self.f.append(module)\n","        # encoder\n","        self.f = nn.Sequential(*self.f)\n","        # projection head\n","        self.g = nn.Sequential(nn.Linear(512, 1024, bias=False), nn.BatchNorm1d(1024),\n","                               nn.ReLU(inplace=True), nn.Linear(1024, feature_dim, bias=True)) \n","\n","    def forward(self, x):\n","        x = self.f(x)\n","        feature = torch.flatten(x, start_dim=1)\n","        out = self.g(feature)\n","        return F.normalize(feature, dim=-1), out\n","\n","\n","class Supervised_ResNet18(nn.Module):\n","    def __init__(self, num_class=10):\n","        super(Supervised_ResNet18, self).__init__()\n","\n","        self.f = []\n","        for name, module in resnet18().named_children():\n","            if name == 'conv1':\n","                module = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","            if not isinstance(module, nn.Linear) and not isinstance(module, nn.MaxPool2d):\n","                self.f.append(module)\n","        # encoder\n","        self.f = nn.Sequential(*self.f)\n","        # fully connected layer\n","        self.fc = nn.Sequential(nn.Linear(512, num_class, bias=True))\n","\n","    def forward(self, x):\n","        x = self.f(x)\n","        feature = torch.flatten(x, start_dim=1)\n","        out = self.fc(feature)\n","        return out\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nghr4pRTWgNu"},"source":["class CIFAR10Pair(datasets.CIFAR10):\n","    \"\"\"CIFAR10 Dataset.\n","    \"\"\"\n","\n","    def __getitem__(self, index):\n","        img, target = self.data[index], self.targets[index]\n","        img = Image.fromarray(img)\n","\n","        if self.transform is not None:\n","            pos_1 = self.transform(img)\n","            pos_2 = self.transform(img)\n","\n","        if self.target_transform is not None:\n","            target = self.target_transform(target)\n","\n","        return pos_1, pos_2, target\n","\n","# for own dataset\n","class CustomDataPair(datasets.ImageFolder):\n","\n","    def __getitem__(self, index):\n","        path, target = self.samples[index]\n","        sample = self.loader(path)\n","        if self.transform is not None:\n","            pos_1 = self.transform(sample)\n","            pos_2 = self.transform(sample)\n","        if self.target_transform is not None:\n","            target = self.target_transform(target)\n","\n","        return pos_1, pos_2, target"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qHulc2dLUWcM"},"source":["# SimCLR train\n","def SimCLR_train(encoder_q, data_loader, train_optimizer):\n","    encoder_q.train()\n","    total_loss, total_num, train_bar = 0.0, 0, tqdm(data_loader)\n","    for x_q, x_k, _ in train_bar:\n","        x_q, x_k = x_q.cuda(non_blocking=True), x_k.cuda(non_blocking=True)\n","        _, view_q = encoder_q(x_q)\n","        _, view_k = encoder_q(x_k)\n","\n","        batch_size = view_q.size(0)\n","        feature_dim = view_q.size(1)\n","\n","        mask = torch.eye(batch_size, dtype=torch.bool).to(x_q.device)\n","        # [Batch, Batch]\n","        score1 = torch.mm(view_q, view_q.t().contiguous())\n","        score2 = torch.mm(view_k, view_k.t().contiguous())\n","        # [Batch, Batch-1]\n","        score1 = score1[~mask].view(batch_size, -1)\n","        score2 = score2[~mask].view(batch_size, -1)\n","        # [Batch, Batch]\n","        score3 = torch.mm(view_q, view_k.t().contiguous())        \n","        score4 = torch.mm(view_k, view_q.t().contiguous())\n","        # [Batch, Batch+Batch-1]\n","        score3 = torch.cat([score3, score1], dim=-1)\n","        score4 = torch.cat([score4, score2], dim=-1)\n","\n","\n","        # compute loss\n","        labels = torch.arange(batch_size, dtype=torch.long, device=x_q.device)\n","        loss1 = F.cross_entropy(score3 / temperature, labels)\n","        loss2 = F.cross_entropy(score4 / temperature, labels)\n","        loss = (loss1+loss2)/2.0\n","\n","\n","        train_optimizer.zero_grad()\n","        loss.backward()\n","        train_optimizer.step()\n","\n","        total_num += batch_size\n","        total_loss += loss.item() * batch_size\n","        train_bar.set_description('Train Epoch: [{}/{}] Loss: {:.4f}'.format(epoch, epochs, total_loss / total_num))\n","\n","    return total_loss / total_num"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Eeu3TEjW3S8"},"source":["# MoCo train\n","def MoCo_train(encoder_q, encoder_k, data_loader, train_optimizer):\n","    global memory_queue\n","    encoder_q.train()\n","    total_loss, total_num, train_bar = 0.0, 0, tqdm(data_loader)\n","    for x_q, x_k, _ in train_bar:\n","        x_q, x_k = x_q.cuda(non_blocking=True), x_k.cuda(non_blocking=True)\n","        _, query = encoder_q(x_q)\n","        _, key = encoder_k(x_k)\n","        \n","        batch_size = query.size(0)\n","        feature_dim = query.size(1)\n","\n","        score_pos = torch.bmm(query.view(batch_size, 1, feature_dim), key.view(batch_size, feature_dim, 1))\n","        score_pos = torch.squeeze(score_pos, dim=1)\n","        score_neg = torch.mm(query, memory_queue.t().contiguous())\n","        # [B, 1+M]\n","        out = torch.cat([score_pos, score_neg], dim=1)\n","        # compute loss\n","        loss = F.cross_entropy(out / temperature, torch.zeros(batch_size, dtype=torch.long, device=x_q.device))\n","\n","        #---------------- symmetry loss can improve the performance\n","        _, query2 = encoder_q(x_k)\n","        _, key2 = encoder_k(x_q)\n","\n","        score_pos = torch.bmm(query2.view(batch_size, 1, feature_dim), key2.view(batch_size, feature_dim, 1))\n","        score_pos = torch.squeeze(score_pos, dim=1)\n","        score_neg = torch.mm(query2, memory_queue.t().contiguous())\n","        # [B, 1+M]\n","        out = torch.cat([score_pos, score_neg], dim=1)\n","        # compute loss\n","        loss2 = F.cross_entropy(out / temperature, torch.zeros(batch_size, dtype=torch.long, device=x_q.device))\n","        #----------------\n","        loss = (loss + loss2)/2.0\n","\n","\n","        train_optimizer.zero_grad()\n","        loss.backward()\n","        train_optimizer.step()\n","\n","        # momentum update\n","        for parameter_q, parameter_k in zip(encoder_q.parameters(), encoder_k.parameters()):\n","            parameter_k.data.copy_(parameter_k.data * momentum + parameter_q.data * (1.0 - momentum))\n","        # update queue\n","        memory_queue = torch.cat((memory_queue, key, key2), dim=0)[2*batch_size:]\n","\n","        total_num += batch_size\n","        total_loss += loss.item() * batch_size\n","        train_bar.set_description('Train Epoch: [{}/{}] Loss: {:.4f}'.format(epoch, epochs, total_loss / total_num))\n","\n","    return total_loss / total_num"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k79kTIAnjlhm"},"source":["# BYOL train\n","def BYOL_loss(x, y):\n","        x = F.normalize(x, dim=1)\n","        y = F.normalize(y, dim=1)\n","        return 2 - 2 * (x * y).sum(dim=-1)\n","    \n","def BYOL_train(encoder_q, predict_layer, encoder_k, data_loader, train_optimizer):\n","    encoder_q.train()\n","    predict_layer.train()\n","    \n","    total_loss, total_num, train_bar = 0.0, 0, tqdm(data_loader)\n","    for x_q, x_k, _ in train_bar:\n","        x_q, x_k = x_q.cuda(non_blocking=True), x_k.cuda(non_blocking=True)\n","        \n","        \n","        _, query1 = encoder_q(x_q)\n","        _, query2 = encoder_q(x_k)\n","        pred1 = predict_layer(query1)\n","        pred2 = predict_layer(query2)\n","\n","        with torch.no_grad():\n","            _, key2 = encoder_k(x_k)\n","            _, key1 = encoder_k(x_q)\n","            \n","        \n","        loss1 = BYOL_loss(pred1,key2)\n","        loss2 = BYOL_loss(pred2,key1)\n","        loss = (loss1+loss2).mean()\n","\n","        train_optimizer.zero_grad() # 這三步驟是算完loss要更新model參數的步驟，對每個演算法都是通用的\n","        loss.backward()\n","        train_optimizer.step()\n","\n","        # momentum update\n","        for parameter_q, parameter_k in zip(encoder_q.parameters(), encoder_k.parameters()):\n","            parameter_k.data.copy_(parameter_k.data * momentum + parameter_q.data * (1.0 - momentum))\n","\n","        batch_size = query1.size(0)\n","        feature_dim = query1.size(1)\n","        total_num += batch_size\n","        total_loss += loss.item() * batch_size\n","        train_bar.set_description('Train Epoch: [{}/{}] Loss: {:.4f}'.format(epoch, epochs, total_loss / total_num))\n","\n","    return total_loss / total_num"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r-zzIayEjlhn"},"source":["# BarlowTwins train\n","def BarlowTwins_train(encoder_q, data_loader, train_optimizer, lambda_param):\n","    encoder_q.train()\n","    \n","    total_loss, total_num, train_bar = 0.0, 0, tqdm(data_loader)\n","    for x_q, x_k, _ in train_bar:\n","        x_q, x_k = x_q.cuda(non_blocking=True), x_k.cuda(non_blocking=True)\n","        _, view_q = encoder_q(x_q)\n","        _, view_k = encoder_q(x_k)\n","\n","        N = view_q.size(0) # batch size\n","        D = view_q.size(1) # feature dimension(output dimension of projection layer\n","\n","        view_q_norm = (view_q - view_q.mean(0)) / view_q.std(0) # NxD\n","        view_k_norm = (view_k - view_k.mean(0)) / view_k.std(0) # NxD\n","\n","        # cross-correlation matrix\n","        c = torch.mm(view_q_norm.t().contiguous(), view_k_norm) / N # DxD \n","        # loss\n","        c_diff = (c - torch.eye(D, device=view_q.device)).pow(2) # DxD\n","        # multiply off-diagonal elems of c_diff by lambda\n","        c_diff[~torch.eye(D, dtype=bool)] *= lambda_param\n","        loss = c_diff.sum()\n","\n","        # loss反向傳播+優化器更新模型參數\n","        train_optimizer.zero_grad()\n","        loss.backward()\n","        train_optimizer.step()\n","\n","        total_num += batch_size\n","        total_loss += loss.item() * batch_size\n","        train_bar.set_description('Train Epoch: [{}/{}] Loss: {:.4f}'.format(epoch, epochs, total_loss / total_num))\n","\n","    return total_loss / total_num"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tqX6ozRUH-Si"},"source":["#supervised learning, train with labels\n","def Supervised_train(net, data_loader, train_optimizer):\n","    net.train()\n","    \n","    total_loss, total_correct_1, total_correct_5, total_num, data_bar = 0.0, 0.0, 0.0, 0, tqdm(data_loader)\n","    with torch.enable_grad():\n","        for data, target in data_bar:\n","            data, target = data.cuda(non_blocking=True), target.cuda(non_blocking=True)\n","            \n","            out = net(data)\n","            loss = F.cross_entropy(out, target)\n","\n","            train_optimizer.zero_grad()\n","            loss.backward()\n","            train_optimizer.step()\n","\n","            total_num += data.size(0)\n","            total_loss += loss.item() * data.size(0)\n","            prediction = torch.argsort(out, dim=-1, descending=True)\n","            total_correct_1 += torch.sum((prediction[:, 0:1] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n","            total_correct_5 += torch.sum((prediction[:, 0:5] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n","\n","            data_bar.set_description('{} Epoch: [{}/{}] Loss: {:.4f} ACC@1: {:.2f}% ACC@5: {:.2f}%'\n","                                     .format('Train', epoch, epochs, total_loss / total_num,\n","                                             total_correct_1 / total_num * 100, total_correct_5 / total_num * 100))\n","\n","    return total_loss / total_num, total_correct_1 / total_num * 100, total_correct_5 / total_num * 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BukFXtDpXEpC"},"source":["# knn測試準確率，非Linear Protocol，會比較不準\n","def SSL_test(net, memory_data_loader, test_data_loader):\n","    net.eval()\n","    total_top1, total_top5, total_num, feature_bank = 0.0, 0.0, 0, []\n","    with torch.no_grad():\n","        # generate feature bank\n","        for data, _, target in tqdm(memory_data_loader, desc='Feature extracting'):\n","            feature, out = net(data.cuda(non_blocking=True))\n","            feature_bank.append(feature)\n","        # [D, N]\n","        feature_bank = torch.cat(feature_bank, dim=0).t().contiguous()\n","        # [N]\n","        feature_labels = torch.tensor(memory_data_loader.dataset.targets, device=feature_bank.device)\n","        # loop test data to predict the label by weighted knn search\n","        test_bar = tqdm(test_data_loader)\n","        for data, _, target in test_bar:\n","            data, target = data.cuda(non_blocking=True), target.cuda(non_blocking=True)\n","            feature, out = net(data)\n","\n","            total_num += data.size(0)\n","            # compute cos similarity between each feature vector and feature bank ---> [B, N]\n","            sim_matrix = torch.mm(feature, feature_bank)\n","            # [B, K]\n","            sim_weight, sim_indices = sim_matrix.topk(k=k, dim=-1)\n","            # [B, K]\n","            sim_labels = torch.gather(feature_labels.expand(data.size(0), -1), dim=-1, index=sim_indices)\n","            sim_weight = (sim_weight / temperature).exp()\n","\n","            # counts for each class\n","            one_hot_label = torch.zeros(data.size(0) * k, c, device=sim_labels.device)\n","            # [B*K, C]\n","            one_hot_label = one_hot_label.scatter(dim=-1, index=sim_labels.view(-1, 1), value=1.0)\n","            # weighted score ---> [B, C]\n","            pred_scores = torch.sum(one_hot_label.view(data.size(0), -1, c) * sim_weight.unsqueeze(dim=-1), dim=1)\n","\n","            pred_labels = pred_scores.argsort(dim=-1, descending=True)\n","            total_top1 += torch.sum((pred_labels[:, :1] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n","            total_top5 += torch.sum((pred_labels[:, :5] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n","            test_bar.set_description('Test Epoch: [{}/{}] Acc@1:{:.2f}% Acc@5:{:.2f}%'\n","                                     .format(epoch, epochs, total_top1 / total_num * 100, total_top5 / total_num * 100))\n","\n","    return total_top1 / total_num * 100, total_top5 / total_num * 100\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4_C0YFxbWvqa"},"source":["def Supervised_test(net, test_data_loader):\n","    net.eval()\n","\n","    total_loss, total_correct_1, total_correct_5, total_num, data_bar = 0.0, 0.0, 0.0, 0, tqdm(test_data_loader)\n","    with torch.no_grad():\n","        for data, target in data_bar:\n","            data, target = data.cuda(non_blocking=True), target.cuda(non_blocking=True)\n","            \n","            out = net(data)\n","\n","            total_num += data.size(0)\n","            prediction = torch.argsort(out, dim=-1, descending=True)\n","            total_correct_1 += torch.sum((prediction[:, 0:1] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n","            total_correct_5 += torch.sum((prediction[:, 0:5] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n","\n","            data_bar.set_description('{} Epoch: [{}/{}] ACC@1: {:.2f}% ACC@5: {:.2f}%'\n","                                     .format('Test', epoch, epochs,\n","                                             total_correct_1 / total_num * 100, total_correct_5 / total_num * 100))\n","\n","    return total_correct_1 / total_num * 100, total_correct_5 / total_num * 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O-ddk_G3x3PL"},"source":["# 如果optimizer是SGD的話，我們根據epoch來調整learning rate，避免learning rate都不變化\n","def adjust_learning_rate(learning_rate, optimizer, epoch, total_epochs, cosine):\n","    lr = learning_rate\n","    lr_decay_rate = 0.2\n","    if cosine:\n","        eta_min = lr * (lr_decay_rate ** 3)\n","        lr = eta_min + (lr - eta_min) * (\n","                1 + math.cos(math.pi * epoch / total_epochs)) / 2\n","    else:\n","        lr_decay_epochs = np.array([math.floor(total_epochs*0.5), math.floor(total_epochs*0.75), math.floor(total_epochs*0.875)])\n","        steps = np.sum(epoch > np.asarray(lr_decay_epochs))\n","        if steps > 0:\n","            lr = lr * (lr_decay_rate ** steps)\n","\n","    print(\"LR:{}\".format(lr))\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VgJQJhTKXVRz","colab":{"base_uri":"https://localhost:8080/","height":364,"referenced_widgets":["b08d9ff6dcad4dcab5e54a001614f863","ab140b1fd20c4df4b5cda9a3215ed13f","06987b938997430dbe31dd08cb06847c","477988b62d454249a067b75b590ce1f1","646106f4847d4797a44a2ed53ac33030","517529527e6048b7ae554c7c7b2fd3ae","e156fd40458b4526b5b57f92818c3d6b","cb32dfbe2d3e47bba40df0e62a286fa3","cd17095258504cfcafcb5b0a7cd72df3","0eed604eda63427cb1773661c4ad21a1","8853432e218c459eb22d22146dc25475"]},"executionInfo":{"status":"ok","timestamp":1638447290034,"user_tz":-480,"elapsed":1243700,"user":{"displayName":"林同軒","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17956594846841709825"}},"outputId":"77eea324-052d-47b5-802d-08281adcf14f"},"source":["# 訓練主程式\n","if __name__ == '__main__':\n","    \n","    feature_dim = 1024  # 映射後向量維度, 若是使用BarlowTwins需要改成1024以上，其餘128就可以\n","    m = 4096 # moco queue大小\n","    temperature, momentum = 0.1, 0.99 # 超參數設置\n","    k = 200 # knn中的k(此為非正式測試準確度的方式，正式方式還是以Linear Protocol為主)\n","    batch_size = 512\n","    epochs = 3\n","    model_name = 'resnet18' # 特徵抽取器的架構\n","    Learning_method = 'BarlowTwins' # SimCLR, MoCo, BYOL, BarlowTwins, Supervised->this is a basic supervised learning method\n","    LR = 0.5\n","\n","    # 準備資料集，監督式學習用普通的cifar10，自監督學習要用回傳兩張經過變換的圖片\n","    if Learning_method == 'Supervised':\n","        train_data = datasets.CIFAR10(root='./dataset', train=True, transform=supervised_train_transform, download=True)\n","        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True, drop_last=True)\n","        test_data = datasets.CIFAR10(root='./dataset', train=False, transform=test_transform, download=True)\n","        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n","    else:\n","        train_data = CIFAR10Pair(root='./dataset', train=True, transform=SSL_train_transform, download=True)\n","        # train_data = CustomDataPair(root='~/cutone_data/cifar10_pic_10per/train/', transform=train_transform)\n","        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True, drop_last=True)\n","        memory_data = CIFAR10Pair(root='./dataset', train=True, transform=test_transform, download=True)\n","        # memory_data = CustomDataPair(root='~/cutone_data/cifar10_pic_10per/train/', transform=test_transform)\n","        memory_loader = DataLoader(memory_data, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n","        test_data = CIFAR10Pair(root='./dataset', train=False, transform=test_transform, download=True)\n","        # test_data = CustomDataPair(root='~/cutone_data/cifar10_pic_10per/test/', transform=test_transform)\n","        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n","\n","    # 設定各個演算法的訓練模型、優化器\n","    if Learning_method == 'SimCLR':\n","        print('running SimCLR')\n","        model_q = SSL_ResNet18(feature_dim).cuda()\n","        optimizer = optim.SGD(model_q.parameters(), lr=LR, momentum=0.9, weight_decay=1e-6)\n","    elif Learning_method == 'MoCo':\n","        print('running MoCo')\n","        model_q = SSL_ResNet18(feature_dim).cuda()\n","        model_k = SSL_ResNet18(feature_dim).cuda()\n","        # init memory queue as unit random vector ---> [M, D]\n","        memory_queue = F.normalize(torch.randn(m, feature_dim).cuda(), dim=-1)\n","        optimizer = optim.SGD(model_q.parameters(), lr=LR, momentum=0.9, weight_decay=1e-6)\n","    elif Learning_method == 'BYOL':\n","        print('running BYOL')\n","        model_q = BYOL_ResNet18(feature_dim).cuda()\n","        model_k = BYOL_ResNet18(feature_dim).cuda()\n","        pred_model = Prediction_Layer().cuda()\n","        optimizer = optim.SGD(list(model_q.parameters())+list(pred_model.parameters()), \n","                                  lr=LR, momentum=0.9, weight_decay=1e-6)\n","    elif Learning_method == 'BarlowTwins':\n","        print('running BarlowTwins')\n","        model_q = BarlowTwins_ResNet18(feature_dim).cuda()\n","        optimizer = optim.SGD(model_q.parameters(), lr=LR, momentum=0.9, weight_decay=1e-6)\n","    elif Learning_method == 'Supervised':\n","        print('running Supervised Learning')\n","        model_q = Supervised_ResNet18(num_class=len(train_data.classes)).cuda()\n","        optimizer = optim.SGD(model_q.parameters(), lr=LR, momentum=0.9, weight_decay=1e-6)\n","    else:\n","        raise ValueError('Learning method is either SimCLR, MoCo, BYOL, BarlowTwins, Supervised.')\n","    \n","    \n","    \n","    # for MoCo, BYOL演算法，初始化model_k(不使用gradient更新的模型)\n","    if Learning_method == 'MoCo' or Learning_method == 'BYOL':\n","        for param_q, param_k in zip(model_q.parameters(), model_k.parameters()):\n","            param_k.data.copy_(param_q.data)\n","            param_k.requires_grad = False\n","    \n","\n","    # train 資料類別數\n","    c = len(test_data.classes)\n","    \n","    \n","\n","    # training loop\n","    results = {'train_loss': [], 'total_time': [], 'test_acc@1': [], 'test_acc@5': []}\n","    save_name_pre = '{}_{}_f{}_q{}_t{}_m{}_k{}_B{}_e{}'.format(Learning_method, model_name, feature_dim, m, temperature, momentum, k, batch_size, epochs)\n","    best_acc = 0.0\n","    begin_time = time.time()\n","    for epoch in range(1, epochs + 1):\n","        if type(optimizer) is optim.SGD: \n","            adjust_learning_rate(LR, optimizer, epoch, epochs, cosine=True)\n","        \n","        if Learning_method == 'MoCo':\n","            train_loss = MoCo_train(model_q, model_k, train_loader, optimizer)\n","        elif Learning_method == 'SimCLR':\n","            train_loss = SimCLR_train(model_q, train_loader, optimizer)\n","        elif Learning_method == 'BYOL':\n","            train_loss = BYOL_train(model_q, pred_model, model_k, train_loader, optimizer)\n","        elif Learning_method == 'BarlowTwins':\n","            train_loss = BarlowTwins_train(model_q, train_loader, optimizer, lambda_param=0.005) # 可以動手改一下lambda_param，這參數對於模型的影響蠻大的\n","        elif Learning_method == 'Supervised':\n","            train_loss, train_acc1, train_acc5 = Supervised_train(model_q, train_loader, optimizer)\n","        else:\n","            raise ValueError('Learning method is either SimCLR, MoCo, BYOL, BarlowTwins, Supervised')\n","        \n","        \n","        results['train_loss'].append(train_loss)\n","        results['total_time'].append(time.time()-begin_time)\n","        if Learning_method != 'Supervised':\n","            test_acc_1, test_acc_5 = SSL_test(model_q, memory_loader, test_loader)\n","        else:\n","            test_acc_1, test_acc_5 = Supervised_test(model_q, test_loader)\n","\n","        results['test_acc@1'].append(test_acc_1)\n","        results['test_acc@5'].append(test_acc_5)\n","        \n","        # save statistics\n","        if not os.path.exists('./results'):\n","            os.mkdir('./results')\n","        data_frame = pd.DataFrame(data=results, index=range(1, epoch + 1))\n","        data_frame.to_csv('./results/{}_results.csv'.format(save_name_pre), index_label='epoch')\n","        # if test_acc_1 > best_acc:\n","        #     best_acc = test_acc_1\n","        #     torch.save(model_q.state_dict(), 'results/{}_model.pth'.format(save_name_pre))\n","        # save model every 50 epoch\n","        if epoch % 50 == 0:\n","            torch.save(model_q.state_dict(), './results/{}_model.pth'.format(save_name_pre))\n","    \n","    torch.save(model_q.state_dict(), './results/{}_model.pth'.format(save_name_pre)) "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dataset/cifar-10-python.tar.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b08d9ff6dcad4dcab5e54a001614f863","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/170498071 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./dataset/cifar-10-python.tar.gz to ./dataset\n","Files already downloaded and verified\n","Files already downloaded and verified\n","running BarlowTwins\n","LR:0.376\n"]},{"output_type":"stream","name":"stderr","text":["Train Epoch: [1/3] Loss: 676.3565: 100%|██████████| 97/97 [05:54<00:00,  3.65s/it]\n","Feature extracting: 100%|██████████| 98/98 [00:37<00:00,  2.59it/s]\n","Test Epoch: [1/3] Acc@1:25.09% Acc@5:75.32%: 100%|██████████| 20/20 [00:13<00:00,  1.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["LR:0.12800000000000006\n"]},{"output_type":"stream","name":"stderr","text":["Train Epoch: [2/3] Loss: 627.9661: 100%|██████████| 97/97 [05:52<00:00,  3.63s/it]\n","Feature extracting: 100%|██████████| 98/98 [00:37<00:00,  2.60it/s]\n","Test Epoch: [2/3] Acc@1:25.49% Acc@5:78.22%: 100%|██████████| 20/20 [00:13<00:00,  1.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["LR:0.004000000000000001\n"]},{"output_type":"stream","name":"stderr","text":["Train Epoch: [3/3] Loss: 596.8053: 100%|██████████| 97/97 [05:53<00:00,  3.65s/it]\n","Feature extracting: 100%|██████████| 98/98 [00:37<00:00,  2.60it/s]\n","Test Epoch: [3/3] Acc@1:25.45% Acc@5:78.09%: 100%|██████████| 20/20 [00:13<00:00,  1.51it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"f1WFJmMduVrv"},"source":["## 以下是讀取特徵抽取模型，並加上fully connected layer做Linear Evaluation的測試（給SSL做測試的方法！監督試學習不建議！）"]},{"cell_type":"code","metadata":{"id":"bLW53G011l2B"},"source":["# 讀取訓練完的模型，並且用Linear protocol方式評估模型好壞\n","model_path = ''\n","print(model_path)\n","epochs = 50\n","model_name = 'SSL_resnet18' # SSL_resnet50, SSL_resnet18, Supervised\n","save_folder = './results/'\n","batch_size = 256\n","\n","# 準備資料集，可能要注意一下train_data要用怎樣的transform\n","train_data = datasets.CIFAR10(root='./dataset', train=True, transform=SSL_train_transform, download=True)\n","# train_data = datasets.ImageFolder(root='./cifar10_10percent/train', transform=train_transform)\n","train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True, drop_last=True)\n","test_data = datasets.CIFAR10(root='./dataset', train=False, transform=test_transform, download=True)\n","# test_data = datasets.ImageFolder(root='./cifar10_10percent/test', transform=test_transform)\n","test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zRYrrKP61rhJ"},"source":["class Net_18(nn.Module):\n","    def __init__(self, num_class, pretrained_path):\n","        super(Net_18, self).__init__()\n","\n","        # encoder\n","        self.f = SSL_ResNet18().f\n","        # classifier\n","        self.fc = nn.Linear(512, num_class, bias=True)\n","        self.load_state_dict(torch.load(pretrained_path, map_location='cpu'), strict=False)\n","\n","    def forward(self, x):\n","        x = self.f(x)\n","        feature = torch.flatten(x, start_dim=1)\n","        out = self.fc(feature)\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VcRriuTTm5LZ"},"source":["def train_evaluation(net, data_loader, train_optimizer):\n","    net.train()\n","\n","    total_loss, total_correct_1, total_correct_5, total_num, data_bar = 0.0, 0.0, 0.0, 0, tqdm(data_loader)\n","    with torch.enable_grad():\n","        for data, target in data_bar:\n","            data, target = data.cuda(non_blocking=True), target.cuda(non_blocking=True)\n","            \n","            out = net(data)\n","            loss = F.cross_entropy(out, target)\n","            \n","            train_optimizer.zero_grad()\n","            loss.backward()\n","            train_optimizer.step()\n","\n","            total_num += data.size(0)\n","            total_loss += loss.item() * data.size(0)\n","            prediction = torch.argsort(out, dim=-1, descending=True)\n","            total_correct_1 += torch.sum((prediction[:, 0:1] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n","            total_correct_5 += torch.sum((prediction[:, 0:5] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n","\n","            data_bar.set_description('{} Epoch: [{}/{}] Loss: {:.4f} ACC@1: {:.2f}% ACC@5: {:.2f}%'\n","                                     .format('Train', epoch, epochs, total_loss / total_num,\n","                                             total_correct_1 / total_num * 100, total_correct_5 / total_num * 100))\n","\n","    return total_loss / total_num, total_correct_1 / total_num * 100, total_correct_5 / total_num * 100\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z4diDMaJjau9"},"source":["def test_evaluation(net, data_loader):\n","    net.eval()\n","\n","    total_loss, total_correct_1, total_correct_5, total_num, data_bar = 0.0, 0.0, 0.0, 0, tqdm(data_loader)\n","    with torch.no_grad():\n","        for data, target in data_bar:\n","            data, target = data.cuda(non_blocking=True), target.cuda(non_blocking=True)\n","            \n","            out = net(data)\n","            loss = F.cross_entropy(out, target)\n","\n","            total_num += data.size(0)\n","            total_loss += loss.item() * data.size(0)\n","            prediction = torch.argsort(out, dim=-1, descending=True)\n","            total_correct_1 += torch.sum((prediction[:, 0:1] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n","            total_correct_5 += torch.sum((prediction[:, 0:5] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n","\n","            data_bar.set_description('{} Epoch: [{}/{}] Loss: {:.4f} ACC@1: {:.2f}% ACC@5: {:.2f}%'\n","                                     .format('Test', epoch, epochs, total_loss / total_num,\n","                                             total_correct_1 / total_num * 100, total_correct_5 / total_num * 100))\n","\n","    return total_loss / total_num, total_correct_1 / total_num * 100, total_correct_5 / total_num * 100\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sTlp2QCT1zah"},"source":["if model_name == 'SSL_resnet50':\n","    model = Net_50(num_class=len(train_data.classes), pretrained_path=model_path).cuda()\n","    for param in model.f.parameters():\n","        param.requires_grad = False\n","elif model_name == 'SSL_resnet18':\n","    model = Net_18(num_class=len(train_data.classes), pretrained_path=model_path).cuda()\n","    for param in model.f.parameters():\n","        param.requires_grad = False\n","elif model_name == 'Supervised':\n","    model = Supervised_ResNet18().cuda()\n","    model.load_state_dict(torch.load(model_path), strict=False)\n","    for param in model.f.parameters():\n","        param.requires_grad = False\n","else:\n","    raise ValueError('model is either resnet50 or resnet18')\n","\n","\n","results = {'train_loss': [], 'train_acc@1': [], 'train_acc@5': [], 'test_loss': [], 'test_acc@1': [], 'test_acc@5': []}\n","\n","\n","optimizer = optim.Adam(model.fc.parameters(), lr=1e-2, weight_decay=1e-6)\n","\n","loss_criterion = nn.CrossEntropyLoss()\n","\n","best_acc = 0.0\n","for epoch in range(1, epochs + 1):\n","    train_loss, train_acc_1, train_acc_5 = train_evaluation(model, train_loader, optimizer)\n","    results['train_loss'].append(train_loss)\n","    results['train_acc@1'].append(train_acc_1)\n","    results['train_acc@5'].append(train_acc_5)\n","    test_loss, test_acc_1, test_acc_5 = test_evaluation(model, test_loader)\n","    results['test_loss'].append(test_loss)\n","    results['test_acc@1'].append(test_acc_1)\n","    results['test_acc@5'].append(test_acc_5)\n","    # save statistics\n","    data_frame = pd.DataFrame(data=results, index=range(1, epoch + 1))\n","    data_frame.to_csv('./results/CIFAR10_linear_evaluation.csv', index_label='epoch')\n","    # if test_acc_1 > best_acc:\n","    #     best_acc = test_acc_1\n","    #     torch.save(model.state_dict(), 'results/CIFAR10_linear_model.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VX68VZOfDEw9"},"source":[""],"execution_count":null,"outputs":[]}]}